{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e8c8b0a",
   "metadata": {},
   "source": [
    "Pre-Procesamiento de Imagenes:\n",
    "\n",
    "Se importan librerías para remover los fondos de las imágenes, así como la redimensión de las mismas y colocar las imágenes en blanco y negro para su posterior normalización y etiquetado.\n",
    "\n",
    "Se recorre la carpeta de Raw que contiene los datos crudos de las imágenes hasta recorrer las tres carpetas correspondientes (rock, paper,scissors). Primero remueve el fondo de la imagen, luego la convierte en escala de grises, la redimensiona a 30x20 px y finalmente guarda el resultado en la carpeta correspondiente, cambiando el nombre a processed_XXX (donde XXX es el nombre original del archivo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f24678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from rembg import remove\n",
    "\n",
    "# Ruta a la carpeta data/raw\n",
    "raw_folder = \"../data/raw\"\n",
    "\n",
    "# Recorre cada subcarpeta dentro de data/raw\n",
    "for subfolder in os.listdir(raw_folder):\n",
    "    subfolder_path = os.path.join(raw_folder, subfolder)\n",
    "    \n",
    "    # Verifica si es una carpeta\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        print(f\"Procesando carpeta: {subfolder}\")\n",
    "        \n",
    "        # Recorre cada archivo en la subcarpeta\n",
    "        for file_name in os.listdir(subfolder_path):\n",
    "            file_path = os.path.join(subfolder_path, file_name)\n",
    "            \n",
    "            # Verifica si es una imagen\n",
    "            if file_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                print(f\"Procesando imagen: {file_name}\")\n",
    "                \n",
    "                # Abre la imagen\n",
    "                with Image.open(file_path) as img:\n",
    "                    # Remueve el fondo\n",
    "                    img_no_bg = remove(img)\n",
    "                    \n",
    "                    # Convierte a escala de grises\n",
    "                    img_gray = img_no_bg.convert(\"L\")\n",
    "                    \n",
    "                    # Redimensiona la imagen\n",
    "                    img_resized = img_gray.resize((30, 20))\n",
    "                    \n",
    "                    # Guarda la imagen procesada\n",
    "                    output_path = os.path.join(subfolder_path, f\"processed_{file_name}\")\n",
    "                    img_resized.save(output_path)\n",
    "                    print(f\"Imagen procesada guardada en: {output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd78191b",
   "metadata": {},
   "source": [
    "\n",
    "Normalización de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c297943c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import time  # Para medir el tiempo de ejecución\n",
    "\n",
    "# Función para normalizar un lote de imágenes\n",
    "def normalize_images(batch):\n",
    "    for file_path in batch:\n",
    "        try:\n",
    "            # Abre la imagen\n",
    "            with Image.open(file_path) as img:\n",
    "                # Convierte la imagen a un array numpy y normaliza\n",
    "                img_array = np.array(img) / 255.0\n",
    "                \n",
    "                # Convierte de nuevo a imagen y guarda\n",
    "                normalized_img = Image.fromarray((img_array * 255).astype(np.uint8))\n",
    "                normalized_img.save(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error procesando {file_path}: {e}\")\n",
    "\n",
    "# Función para dividir una lista en lotes\n",
    "def split_into_batches(file_list, batch_size):\n",
    "    for i in range(0, len(file_list), batch_size):\n",
    "        yield file_list[i:i + batch_size]\n",
    "\n",
    "# Función para procesar una carpeta\n",
    "def process_folder(subfolder):\n",
    "    subfolder_path = os.path.join(processed_folder, subfolder)\n",
    "    \n",
    "    # Verifica si es una carpeta\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        print(f\"Procesando carpeta: {subfolder}\")\n",
    "        \n",
    "        # Lista de imágenes en la carpeta\n",
    "        file_list = [\n",
    "            os.path.join(subfolder_path, file_name)\n",
    "            for file_name in os.listdir(subfolder_path)\n",
    "            if file_name.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "        ]\n",
    "        \n",
    "        # Divide las imágenes en lotes de 100\n",
    "        batches = list(split_into_batches(file_list, 100))\n",
    "        \n",
    "        # Normaliza cada lote\n",
    "        for batch in tqdm(batches, desc=f\"Normalizando imágenes en {subfolder}\", unit=\"lote\"):\n",
    "            normalize_images(batch)\n",
    "\n",
    "# Usa ThreadPoolExecutor para procesar varias carpetas al mismo tiempo\n",
    "if __name__ == \"__main__\":\n",
    "    # Ruta a la carpeta data/processed\n",
    "    processed_folder = \"../data/processed\"\n",
    "\n",
    "    # Temporizador para medir el tiempo de ejecución\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Lista de subcarpetas en data/processed\n",
    "    subfolders = [subfolder for subfolder in os.listdir(processed_folder) if os.path.isdir(os.path.join(processed_folder, subfolder))]\n",
    "    print(f\"Inicialización completada en {time.time() - start_time:.2f} segundos\")\n",
    "\n",
    "    # Usa ThreadPoolExecutor para procesar carpetas en paralelo\n",
    "    with ThreadPoolExecutor(max_workers=3) as executor:  # Cambia max_workers según el número de hilos que quieras usar\n",
    "        list(tqdm(executor.map(process_folder, subfolders), total=len(subfolders), desc=\"Procesando carpetas\"))\n",
    "\n",
    "    print(f\"Todas las carpetas procesadas en {time.time() - start_time:.2f} segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492289aa",
   "metadata": {},
   "source": [
    "División y Etiquetado de Imágenes en Conjuntos de Entrenamiento y Testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a52054d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def dividir_y_etiquetar(processed_folder, train_folder, test_folder, train_csv_path, test_csv_path, test_size=0.3):\n",
    "    \"\"\"\n",
    "    Divide las imágenes directamente desde las carpetas de processed en entrenamiento y testeo,\n",
    "    las mueve a sus respectivas carpetas y genera los CSVs correspondientes.\n",
    "    \"\"\"\n",
    "    # Diccionario para almacenar rutas y etiquetas\n",
    "    data = []\n",
    "\n",
    "    # Recorre cada subcarpeta dentro de processed_folder\n",
    "    label_map = {\"rock\": 0, \"paper\": 1, \"scissors\": 2}\n",
    "    subfolders = [subfolder for subfolder in os.listdir(processed_folder) if os.path.isdir(os.path.join(processed_folder, subfolder))]\n",
    "    for subfolder in tqdm(subfolders, desc=\"Procesando subcarpetas\"):\n",
    "        subfolder_path = os.path.join(processed_folder, subfolder)\n",
    "        label = label_map.get(subfolder.lower(), -1)\n",
    "        if label == -1:\n",
    "            print(f\"Carpeta desconocida: {subfolder}. Ignorando...\")\n",
    "            continue\n",
    "\n",
    "        # Recorre cada archivo en la subcarpeta\n",
    "        file_list = [os.path.join(subfolder_path, file_name) for file_name in os.listdir(subfolder_path) if file_name.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        for file_path in file_list:\n",
    "            data.append({\"path\": file_path, \"label\": label})\n",
    "\n",
    "    # Convierte los datos a un DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Divide los datos en entrenamiento y testeo\n",
    "    train_df, test_df = train_test_split(df, test_size=test_size, random_state=42, stratify=df[\"label\"])\n",
    "\n",
    "    # Crea las carpetas de destino\n",
    "    os.makedirs(train_folder, exist_ok=True)\n",
    "    os.makedirs(test_folder, exist_ok=True)\n",
    "\n",
    "    # Mueve las imágenes de entrenamiento con barra de progreso\n",
    "    print(\"Moviendo imágenes de entrenamiento...\")\n",
    "    for _, row in tqdm(train_df.iterrows(), total=len(train_df), desc=\"Entrenamiento\"):\n",
    "        label_folder = os.path.join(train_folder, str(row[\"label\"]))\n",
    "        os.makedirs(label_folder, exist_ok=True)\n",
    "        shutil.copy(row[\"path\"], label_folder)\n",
    "\n",
    "    # Mueve las imágenes de testeo con barra de progreso\n",
    "    print(\"Moviendo imágenes de testeo...\")\n",
    "    for _, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Testeo\"):\n",
    "        label_folder = os.path.join(test_folder, str(row[\"label\"]))\n",
    "        os.makedirs(label_folder, exist_ok=True)\n",
    "        shutil.copy(row[\"path\"], label_folder)\n",
    "\n",
    "    # Guardar los conjuntos en archivos CSV separados\n",
    "    train_df.to_csv(train_csv_path, index=False)\n",
    "    test_df.to_csv(test_csv_path, index=False)\n",
    "\n",
    "    print(f\"Conjunto de entrenamiento guardado en: {train_csv_path}\")\n",
    "    print(f\"Conjunto de testeo guardado en: {test_csv_path}\")\n",
    "\n",
    "# Rutas de las carpetas y archivos\n",
    "processed_folder = \"../data/processed\"\n",
    "train_folder = \"../data/training\"\n",
    "test_folder = \"../data/test\"\n",
    "train_csv_path = \"../data/training_labels.csv\"\n",
    "test_csv_path = \"../data/test_labels.csv\"\n",
    "\n",
    "# Divide y etiqueta directamente\n",
    "dividir_y_etiquetar(processed_folder, train_folder, test_folder, train_csv_path, test_csv_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
